\chapter*{Abstract}

This thesis discusses a general method for the global optimization of expensive blackbox functions: sequential model-based optimization. `SMBO' works by iteratively fitting a prediction model to available data, and analyzing that model to inform further data-gathering, so as to generate another model with even greater predictive power. By recursively iterating this process, using successive prediction models to bootstrap ever-better models, good solutions are found to hard optimization problems.

This thesis starts in mathematical statistics, and ends in computer science and software design. I will first describe the SMBO process in general: its history, applications, and relevance to optimization today. I will then rigorously present a paradigmatic example of SMBO, the `EGO Algorithm' of Jones et al. A major goal of this thesis is to build a robust implementation of sequential model-based optimization capable of optimizing real-world processes. Thus I also include a detailed methods section presenting my Python package, \texttt{smbo}, a modular SMBO framework. The full documentation of \texttt{smbo} is also included as an appendix.