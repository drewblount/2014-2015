\chapter{A Python Package for SMBO} \label{ch:code}


In exploring this topic, I have built a Python package for performing sequential model-based optimization, simply named \texttt{smbo}. My goal in making it was to construct well-made code, that will be immediately useful as a pedagogical tool (indeed, it was used to generate several figures in this thesis, such as Fig. \ref{}), open source and available online, and documented and designed such that further development of the code base is easy. Perhaps some day \texttt{smbo} will evolve into a cutting-edge free optimization package, used to optimize all sorts of blackbox functions all over the globe, maintained by an international team of elite open-source hackers. Presently, the project is more humble. As of submitting this thesis, the package only implements the EGO algorithm, though its modular, hybrid object-oriented/functional construction allows for further SMBO processes to be defined and implemented easily. \texttt{smbo} is available on the Python Package Index, and can be downloaded and installed with a single command on any computer with Python 2.7.9 or later.\footnote{\texttt{sudo pip install smbo}}

As a good portion of the work in this thesis went into software design and engineering (subjects not taught at Reed College), I will here present the code behind the \texttt{smbo} package on the highest level. This discussion will inform the reader's mathematical understanding of SMBO processes, covering design decisions, identifying runtime bottlenecks, and the crucial components upon which the performance of any SMBO implementation rely. This chapter will also serve as an introduction to the official documentation of the \texttt{smbo} package, which is included as an appendix to this thesis.

\section{Design}\label{sec:design}

The three-stage SMBO cycle, illustrated earlier in Figure \ref{fig:smbo_cycle}, presents a clear opportunity for a modular implementation of sequential model-based optimizers. I will present the \texttt{smbo} class as it relates to these thee stages, which can be conceived of mathematically as three functional components: an objective function $F$, a model-producing function $M$, and a sample-point-selecting function $S$. Where $X$ denotes a point in $F$'s input space, and $\mathbf{X},\mathbf{Y}$ represent vectors of $X$s and their corresponding $F(X)$s, the three stages can expressed functionally as,

\begin{enumerate}
\item $F(\mathbf{X})=\mathbf{Y}$
\item $M(\mathbf{X},\mathbf{Y}) = (\hat{y},\hat{err}_{\hat{y}})$
\item $S(\hat{y},\hat{err}_{\hat{y}}) = x_{new}$.
\end{enumerate}

\subsection{\texttt{smb$\_$optimizer}}

The technical goal of the \texttt{smbo} package is to provide a class, called \texttt{smb$\_$optimizer}, which generically handles and passes arguments between the above three functions to perform the iterative SMBO process. Since this thesis is largely concerned with the case where $S$ is defined by expected improvement maximization (Section \ref{sec:exp_imp}), this stage of the process is implemented by a fixed class method of \texttt{smb$\_$optimizer}, called \texttt{sample}. The other two functions, $F$ and $M$, are callables passed upon initialization to the \texttt{smb$\_$optimizer} class. This information is illustrated on the familiar SMBO loop in Figure \ref{fig:smbo_loop_II}. Figure \ref{fig:smb_opt_doc} is a summary of the official documentation for the \texttt{smb$\_$optimizer} class, listing all of the high-level methods used in iterating the SMBO loop.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.75\textwidth]{smbo_loop_II}
	\caption{An instantiation of an SMBO process consists of a single \texttt{smb$\_$optimizer} object. Here the SMBO loop is labeled with the type of its implementation in the \texttt{smb$\_$optimizer} class.}
	\label{fig:smbo_loop_II}

\end{figure}


% The smb_optimizer documentation
\begin{minipage}{\textwidth}
\begin{framed}
\input{docs/smb_optimizer.tex}
\end{framed}

\captionof{figure}{A summary of the documentation of the \texttt{smb$\_$optimizer} class. To find a global minimum, initialize an \texttt{smb\_optimizer}, call \texttt{take\_samples}, then look at \texttt{f\_min}.} \label{fig:smb_opt_doc}

\end{minipage}




The EGO algorithm, our prototypical SMBO process, is defined by a particular choice of modeller $M$, i.e., the DACE model. This is accomplished by a DACE function \emph{and} a class in the \texttt{smbo.modellers} module. This is the primary component of \texttt{smbo} meriting the description ``functional/object-oriented hybrid'' mentioned in the introduction to this chapter. 

The class \texttt{dace$\_$model} has various methods to implement the calculations defined and derived in Chapter \ref{ch:ego}, including the formulation of $\hat{y}$ and $\hat{err}_{\hat{Y}}$. The functional wrapper $dace_function$ behaves exactly as the ideal functional modeller $M(\mathbf{X},\mathbf{Y}) = (\hat{y},\hat{err}_{\hat{y}})$. That is to say, \texttt{dace$\_$function} takes as input two vectors $(\mathbf{X},\mathbf{Y})$, uses them to initialize an instance of the \texttt{dace$\_$model} class, then retrieves $\hat{y}$ and $\hat{err}_{\hat{Y}}$ using methods of that \texttt{dace$\_$model}, returning them as output. A summary of the documentation of \texttt{dace$\_$function} and \texttt{dace$\_$model} is shown in \ref{fig:dace_doc}.


% The dace documentation
\begin{minipage}{\textwidth}
\begin{framed}
\input{docs/dace.tex}
\end{framed}

\captionof{figure}{A summary of the documentation of the \code{dace} model class. An object of class \code{smb\_optimizer} (Figure \ref{fig:smb_opt_doc}) would take \code{dace\_function} as its \code{modeller} argument. Even though the \code{smb\_optimizer} is only aware of this function, each function call initializes a \code{dace} object, which stays alive behind the scenes as long as its \code{predict} and/or \code{pred\_err} methods are being actively called, which is often, as these form the \code{pred\_y} and \code{pred\_err} attributes of the \code{smb\_optimizer}.} \label{fig:dace_doc}

\end{minipage}



There were two factors that influenced the decision to implement the DACE model in this function-wrapped-class kind of way. First, there is the standard conceptual appeal of functional programming---here, we can appreciate the mathematical purity of a code module that behaves exactly as the generic modelling function $M$ described above, mapping sample points to predictive models. This also makes clear the modular distinction between the central \texttt{smb$\_$optimizer} instance and its \texttt{modeller} attribute---as far as an \texttt{smb$\_$optimizer} instance is concerned, the modeller is a black box function which produces models from sample points. On the other hand, the functional paradigm makes it awkward to allow an \texttt{smbo} package user to experiment with the specifics of a particular modelling function, e.g. to see the results of modifying traditionally internal DACE parameters, such as the characteristic parameter vectors $\mathbf{P}$ and $\mathbf{\theta}$, which define the shape of the response surface, as described in Section \ref{sec:dace}. For example, the statefulness of the \texttt{dace} class allowed my advisor and I to build our intuition regarding the DACE model, by modifying the \texttt{dace} class instance underlying a particular \texttt{smb$\_$optimizer}, and seeing the effects of that change on the plots produced by the \texttt{smb$\_$optimizer}.






\section{Optimization Subroutines}\label{sec:sub_opt}
Each SMBO loop of the EGO algorithm involves two global optimization steps as subroutines. First, the actual fitting of a DACE model to the data is done by selecting the parameters $\mathbf{P}$ and $\mathbf{Q}$ to maximize the likelihood of the data. This process is described in Section \ref{sec:max_lik}, and implemented in \texttt{smbo} with the class method \texttt{smbo.models.dace\_class.exp\_improvement}. Once a model is fit, the next sample point is selected with the SMBO-standard method of maximizing the expected improvement function, \texttt{smbo.smb\_optimizer.exp\_improvement}. It is somewhat striking that in the process of globally optimizing an objective function, these two functions, both defined in terms of the objective data, are optimized many times as subroutines. Of course, the efficiency of the entire SMBO optimization process rests on the assumption that it is much easier to evaluate and optimize these models, of likelihood and expected improvement, than to evaluate the black box objective function. 

These two optimizations can take advantage of known mathematical properties of the functions at hand; they do not share the black box assumption of the larger optimization task. The methods of \cite{jones_efficient_1998} in fact don't even optimize the expected improvement function explicitly, but a mathematically simpler function that underestimates improvement and is easier to optimize (see Section 4.1 of \cite{jones_efficient_1998}). It is worth noting that this craftiness is intended to find a good solution more quickly, not necessarily a better solution, to the expected improvement optimization problem. Despite the computational benefits of this approach, several considerations led to the use of fairly generic function optimization methods within these optimization subroutines of \texttt{smbo}.

Currently, these optimizations are handled by methods of the popular and trusted [how could I cite this?] SciPy library for Python. A major reason to use SciPy is pragmatic: it can be trusted to find good solutions quickly, both by the user of the \texttt{smb\_optimizer} class and and the prospective user or contributor to the \texttt{smbo} package. As my ambitious goal is for \texttt{smbo} to eventually be an active open-source library, there is also some subjective advantage to affiliating with the most popular optimization library in the Python open-source community; to use the SciPy brand. Most importantly though, this construction is modular in a way that the perhaps craftier method of \citep{jones_efficient_1998} is not; the \texttt{smb\_optimizer} class chooses the next sample points in a way that is agnostic to the mathematics underlying the modeller, and simply dependent on the model surface and its expected error. 

Optimization is a notoriously difficult problem to do well and efficiently (hence the original motivation of this thesis), so it is perhaps unsurprising that the likelihood and expected improvement optimizations have been the worst bottlenecks in the SMBO process. This has been the case both in terms of runtime and overall optimization performance. A slow optimizer subroutine obviously increases the time it takes for a single SMBO loop to be computed, but more importantly, a subroutine that returns significantly sub-optimal solutions to the likelihood and expected improvement problems produces bad predictive models. An example of this is illustrated by example in Fig. \ref{fig:opt_compare}, which shows two DACE models fit to the same data, using identical methods except for specific choice of SciPy optimizer to maximize the likelihood of parameters $P$ and $Q$.

\begin{figure}
        \centering
        \begin{subfigure}[t]{0.5\textwidth}
                \includegraphics[width=\textwidth]{images/likelihood_opt_ex/bad}
                \caption{L-BFGS-B\cite{}, as implemented by Scipy\linebreak[0].optimize\linebreak[0].minimize. }
        \end{subfigure}%
        ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
          %(or a blank line to force the subfigure onto a new line)
        \begin{subfigure}[t]{0.5\textwidth}
                \includegraphics[width=\textwidth]{images/likelihood_opt_ex/good}
                \caption{basinhopping\cite{} global optimization algorithm using COBYLA\cite{} locally, as implemented by Scipy\linebreak[0].optimize\linebreak[0].basinhopping.}
        \end{subfigure}
        \caption{Two DACE predictor models fitted to identical sample points, that differ only in their method of numeric maximization (labelled) of the parameter likelihood function (Eq. \ref{eq:conc_likelihood}). Note that the right prediction model is not only more accurate than the left, but its expected error is smaller everywhere; the prediction is more confident.}\label{fig:opt_compare}
\end{figure}

The optimality of SMBO results depends indirectly, but crucially, on the optimality of the results of these sub-optimizers. The cyclical process works because of each successive model's predictive power in finding the global optimum. The loop is run until, by considering the expected improvement surface, our confidence in having found the global optimum passes a certain threshold. From this we can see that bad predictive models make for an inefficient SMBO loop, because expected improvement is monotonically fixed to predicted error, i.e., more model error means more expected improvement. Poor sub-optimizers make for bad models, which have poor predictive power, which means the SMBO loop will be iterated more times before halting, meaning more calls of the objective function. So, a bad optimizer subroutine will require the objective function to be evaluated more times to get a satisfactory solution to the overall optimization problem. As the premise of this thesis involves a too-expensive blackbox function, this is, of course, bad.

%
%\subsection{Basic Runtime Analysis} \label{sec:runtime}

%Because the premise of this thesis is of an inconveniently-expensive blackbox function, the relevant runtime parameter in this analysis will be the number of objective function evaluations $n$. For convenience, I'll assume that each cycle of the SMBO loop selects only one new sample point, so $n$ is equal to the number of overall SMBO loop iterations.



