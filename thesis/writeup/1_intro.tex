\chapter{Introduction}

Sequential model-based optimization is an accurately named process, because it attempts to optimize functions by developing a sequence of models. The broad idea is this: you want to understand some process's global behavior from a few sample points, and you have a limited ability to collect more data--think of additional samples as available, but expensive. This is often the case with processes that are difficult to observe or simulate.

Given a few sample points, you use the available data to develop a model of the process's behavior.  With this model alone, you could perform simple \emph{model}-based optimization, using it to predict the locations of global optima. In \emph{sequential} model-based optimization, however, we use predictive models in a more clever, bootstrapping way: to predict what further data, if collected, would allow us to improve our model---and thus our predictive ability---the most. In other words, each model is used to generate another, better model. Global optima, or at least very good solutions, are then found by recursively improving the predictive ability of a model.

To make this process more tangible, consider the case of gold-mining, which is a surprisingly deep analogy to the kind of data mining which is explored in this thesis. Imagine that you are a gold-miner, and you own a claim to Valley X. You want to understand where in the valley you could find the most gold, where best to start a mine. Your mining company has drilled five exploratory shafts throughout the valley. You make a map of the valley's gold distribution based on these five samples.

Were you, the gold miner, only interested in model-based optimization, you would use this rudimentary map to predict where the most gold in the valley is, and start your mine there. Say, however, that you have enough resources to drill five more exploratory shafts first. The clever miner then asks themself, ``where should I drill the next exploratory shaft, to best learn about where the gold is most concentrated in the valley?" By leveraging what they have learned from the first five data points, the miner finds the region they would like most to learn about. After drilling the sixth hole in this region, the miner can improve their model of the gold distribution yet again, and ask the same question: ``where should I drill next, to best advance my search for the gold optimum?'' The goal of this thesis is to automate this decision-making process.

\section{Black-Box Functions}
A central notion to this thesis is that of black-box functions and their optimization. Though the black-box function is an intuitive concept for many mathematicians and scientists, I have found in discussing this thesis with others that it is an unfamiliar idea to the layperson, so I will spend a moment making all readers fully comfortable with the notion.

Simply put, a black-box function is a mysterious process that turns inputs into outputs. Though its inner workings are unknown to the user, it does operate by some hidden logic. The task of this thesis is to optimize the behavior of this process without direct access tot he hidden logic inside the black box.

Imagine a literal black box, with some sort of terminal or opening for receiving inputs. If things are put in this box, it spits something out. This thought experiment is illustrated in Fig. \ref{fig:black_box}.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\textwidth]{images/blackbox}
	\caption{A black box: a mysterious but queryable function}
	\label{fig:black_box}

\end{figure}

Now imagine that you are confronted with a black box such as illustrated above, and in particular, one that produces a single numerical output when it is fed input\footnote{In this thesis, we are only concerned with functions that map some $k$ dimensions of input to a single-dimensional numeric output, as this is the standard model for optimization.}. Now imagine I were to assign you the task: in only twenty queries of the box, find a particular input that will induce an output greater than 100. How could you go about this task?

To make things easy, we'll make two assumptions about the hidden function in the box: that it is deterministic, so the same input will always produce the same output; and that similar inputs produce similar outputs. This second assumption is crucial, because it allows you to consider observed blackbox values to predict values you have not seen.

Given those two assumptions, no prior knowledge of the blackbox's workings, and the task, ``get the blackbox to produce a desirable output," what does one do? This thesis rigorously addresses that question.

Now this hypothetical, where you have found a magical box that has hidden math inside, and are for some cause compelled to wrench a desirable output from it, sounds somewhat cartoonish and abstract. Yet it is such a general framework, a huge range of real-world problems can be fit into its mould. How often do humans want to control a process that they do not understand, yet can experiment with? Consider the stock market: inputs are your trading decisions, the black box is the market, and the output is your profit. How many people would like a reliable optimization strategy for \emph{that} blackbox function? Many complex biochemical interactions are dynamical enough that they are extremely difficult to model and predict; one iconic example is of protein folding. Here, too, is a setting where inputs (chemical recipes) can be turned into outputs (chemical reagents, or perhaps biomedical results), though the mechanism that accomplishes that transformation (dynamic chemical reaction networks) is somewhat opaque in its inner workings. 

Another major application of blackbox optimizers, which will be explored further in the conclusion, is that of optimizing the parameters of yet other machine learning algorithms. This task, the problem of \emph{hyperparameter optimization}, seeks to optimize the blackbox function which maps algorithm configurations to algorithm performance. Given a machine learning problem, say, identifying dogs in photographs, it is usually fairly straightforward to a practitioner to decide on a class of algorithm that is well-suited to accomplishing that task, e.g., recurrent neural networks. Simply deciding on a class of solution algorithms is not enough to find a solution, however, as there are invariably a basketful of algorithm parameters which must be set before any learning is even to take place. For example, say you want to solve a problem with a so-called deep neural network: how do you decide how many layers of neurons to include? How many neurons should be in each layer? How do you choose an appropriate learning rate? An intuition for questions like these is a large part of what `expertise' means in the field of machine learning, but it is commonly acknowledged that such expertise often errs on artistry rather than science. Because machine learning systems are big, complex, dynamical (and perhaps emergent) systems, is is very hard to know beforehand how well a certain parameter set will solve a given problem or class of problems. Thus, the selection of hyperparameters is another problem space ripe for sequential model-based optimization.

\section{History}


[Just a few paragraphs here, talk first about actual kriging (which was done for gold) and maybe get a fun historical anecdote] \cite{cressie_kriging_1990}.

[Talk about the EGO paper \citep{jones_efficient_1998}--Hutter calls it the beginning of SMBO, ``limited to optimizing continuous parameters for noise-free functions (i.e., the performance of deterministic algorithms).'' \cite{hutter_sequential_2011} See citation for further discussion of SMBO history. Talk about the background of EGO authors, how Jones worked for GM and one of the case studies in the original paper involved 3D engine component design.]

Mention ``PDT$^{TM}$,'' ProtoLife's ``predictive design technology,'' which is illustrated by a figure very similar to Fig \ref{fig:smbo_cycle} \cite{protolife_pdt_2013}

Talk about Hutter's recent work, maybe Google talk? Perhaps some words about how the ML community isn't particularly interested right now, and is more interested in accomplishing extremely huge-dimensional mapping problems like vision and translation, which are being accomplished by deep nets.




